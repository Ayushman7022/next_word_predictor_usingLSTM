{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z-l5e_dptL91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47edb131-c2b8-466d-9545-667ff9617e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"word.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n"
      ],
      "metadata": {
        "id": "50x3gnJIdzFs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n"
      ],
      "metadata": {
        "id": "ak04mAPHWiMA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "\n"
      ],
      "metadata": {
        "id": "s9edtoa0WtPd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words=len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "tiHaTYJTe8uH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in text.split(\"\\n\"):\n",
        "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(tokens)):\n",
        "        n_gram_seq = tokens[:i+1]  # ✅ Corrected variable name (was n_gram_Seq)\n",
        "        input_sequences.append(n_gram_seq)\n"
      ],
      "metadata": {
        "id": "n3AlnqGWf_va"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sequences[5])"
      ],
      "metadata": {
        "id": "DUcsbqBbk8nS",
        "outputId": "5461a016-6da0-4c62-bd30-c10c2fcbee3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[145, 4790, 1, 1020, 4, 128, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
        "\n"
      ],
      "metadata": {
        "id": "EgQ7c-ofW41y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "v5-WC-H0XAsj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words, output_dim=10, input_length=max_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prqMRpHMXKvz",
        "outputId": "0a9270c2-ca35-4fff-9f58-62e8cbbd8b6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyA0ac2UXNqN",
        "outputId": "5b2654a4-7d5b-4b3b-fe05-536e6bb32a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 40ms/step - accuracy: 0.0570 - loss: 6.6773\n",
            "Epoch 2/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.0718 - loss: 6.0198\n",
            "Epoch 3/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1082 - loss: 5.6390\n",
            "Epoch 4/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1291 - loss: 5.3207\n",
            "Epoch 5/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 40ms/step - accuracy: 0.1403 - loss: 5.0933\n",
            "Epoch 6/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1512 - loss: 4.8805\n",
            "Epoch 7/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1620 - loss: 4.6888\n",
            "Epoch 8/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1706 - loss: 4.5263\n",
            "Epoch 9/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1810 - loss: 4.3667\n",
            "Epoch 10/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.1923 - loss: 4.2209\n",
            "Epoch 11/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2059 - loss: 4.0868\n",
            "Epoch 12/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 40ms/step - accuracy: 0.2181 - loss: 3.9686\n",
            "Epoch 13/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2328 - loss: 3.8424\n",
            "Epoch 14/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2456 - loss: 3.7440\n",
            "Epoch 15/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2596 - loss: 3.6428\n",
            "Epoch 16/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2712 - loss: 3.5490\n",
            "Epoch 17/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2828 - loss: 3.4723\n",
            "Epoch 18/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.2954 - loss: 3.3937\n",
            "Epoch 19/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3051 - loss: 3.3178\n",
            "Epoch 20/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3171 - loss: 3.2520\n",
            "Epoch 21/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3253 - loss: 3.1831\n",
            "Epoch 22/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3332 - loss: 3.1446\n",
            "Epoch 23/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3439 - loss: 3.0681\n",
            "Epoch 24/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3519 - loss: 3.0313\n",
            "Epoch 25/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3623 - loss: 2.9796\n",
            "Epoch 26/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3669 - loss: 2.9301\n",
            "Epoch 27/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3761 - loss: 2.8871\n",
            "Epoch 28/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3812 - loss: 2.8473\n",
            "Epoch 29/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3904 - loss: 2.8019\n",
            "Epoch 30/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.3944 - loss: 2.7829\n",
            "Epoch 31/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4030 - loss: 2.7404\n",
            "Epoch 32/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 40ms/step - accuracy: 0.4063 - loss: 2.7053\n",
            "Epoch 33/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4105 - loss: 2.6858\n",
            "Epoch 34/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4140 - loss: 2.6601\n",
            "Epoch 35/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4187 - loss: 2.6285\n",
            "Epoch 36/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4253 - loss: 2.6030\n",
            "Epoch 37/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4275 - loss: 2.5804\n",
            "Epoch 38/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4316 - loss: 2.5592\n",
            "Epoch 39/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4333 - loss: 2.5449\n",
            "Epoch 40/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4373 - loss: 2.5140\n",
            "Epoch 41/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4404 - loss: 2.5094\n",
            "Epoch 42/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 40ms/step - accuracy: 0.4478 - loss: 2.4704\n",
            "Epoch 43/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4487 - loss: 2.4625\n",
            "Epoch 44/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4524 - loss: 2.4326\n",
            "Epoch 45/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4534 - loss: 2.4224\n",
            "Epoch 46/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4586 - loss: 2.4113\n",
            "Epoch 47/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4612 - loss: 2.3946\n",
            "Epoch 48/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4655 - loss: 2.3749\n",
            "Epoch 49/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4684 - loss: 2.3586\n",
            "Epoch 50/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4678 - loss: 2.3558\n",
            "Epoch 51/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4734 - loss: 2.3309\n",
            "Epoch 52/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4750 - loss: 2.3139\n",
            "Epoch 53/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4754 - loss: 2.3121\n",
            "Epoch 54/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4770 - loss: 2.2992\n",
            "Epoch 55/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4824 - loss: 2.2835\n",
            "Epoch 56/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4861 - loss: 2.2571\n",
            "Epoch 57/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4867 - loss: 2.2667\n",
            "Epoch 58/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4874 - loss: 2.2478\n",
            "Epoch 59/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4902 - loss: 2.2353\n",
            "Epoch 60/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4920 - loss: 2.2381\n",
            "Epoch 61/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4924 - loss: 2.2261\n",
            "Epoch 62/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4891 - loss: 2.2268\n",
            "Epoch 63/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4937 - loss: 2.2046\n",
            "Epoch 64/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4971 - loss: 2.1968\n",
            "Epoch 65/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5001 - loss: 2.1842\n",
            "Epoch 66/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.4983 - loss: 2.1868\n",
            "Epoch 67/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5026 - loss: 2.1710\n",
            "Epoch 68/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5035 - loss: 2.1628\n",
            "Epoch 69/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5046 - loss: 2.1529\n",
            "Epoch 70/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5061 - loss: 2.1486\n",
            "Epoch 71/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5053 - loss: 2.1477\n",
            "Epoch 72/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5079 - loss: 2.1448\n",
            "Epoch 73/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5098 - loss: 2.1252\n",
            "Epoch 74/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5114 - loss: 2.1204\n",
            "Epoch 75/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5105 - loss: 2.1199\n",
            "Epoch 76/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5107 - loss: 2.1109\n",
            "Epoch 77/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5133 - loss: 2.1034\n",
            "Epoch 78/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5131 - loss: 2.0975\n",
            "Epoch 79/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5137 - loss: 2.1004\n",
            "Epoch 80/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5145 - loss: 2.0966\n",
            "Epoch 81/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5170 - loss: 2.0900\n",
            "Epoch 82/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5172 - loss: 2.0830\n",
            "Epoch 83/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5189 - loss: 2.0730\n",
            "Epoch 84/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5165 - loss: 2.0734\n",
            "Epoch 85/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5194 - loss: 2.0661\n",
            "Epoch 86/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5198 - loss: 2.0633\n",
            "Epoch 87/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 40ms/step - accuracy: 0.5220 - loss: 2.0573\n",
            "Epoch 88/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5231 - loss: 2.0503\n",
            "Epoch 89/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5237 - loss: 2.0393\n",
            "Epoch 90/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5225 - loss: 2.0460\n",
            "Epoch 91/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5249 - loss: 2.0377\n",
            "Epoch 92/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5251 - loss: 2.0406\n",
            "Epoch 93/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5272 - loss: 2.0389\n",
            "Epoch 94/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5268 - loss: 2.0327\n",
            "Epoch 95/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5285 - loss: 2.0223\n",
            "Epoch 96/100\n",
            "\u001b[1m3176/3176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 40ms/step - accuracy: 0.5317 - loss: 2.0163\n",
            "Epoch 97/100\n",
            "\u001b[1m 874/3176\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 40ms/step - accuracy: 0.5431 - loss: 1.9627"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                seed_text += ' ' + word\n",
        "                break\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "ZFbpOI4XXP8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(\"I love\", 1))\n",
        "print(predict_next_word(\"machine learning\", 1))"
      ],
      "metadata": {
        "id": "2ZAeIcAjXil3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"next_word_weights.h5\")\n"
      ],
      "metadata": {
        "id": "khRVeQUAmoa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        ""
      ],
      "metadata": {
        "id": "L_J_gcI_XmmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}